{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14df55a8-1792-4ae1-a1c1-c101fa330784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Standard Imports\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg') # Used on HPC machine (suppresses plt.show)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "# Read in hdf5 files\n",
    "import h5py\n",
    "\n",
    "sys.path.insert(1,'/home/aku7cf/torreylabtoolsPy3')\n",
    "\n",
    "# Torreylab Tools\n",
    "import simread.readsubfHDF5 as rsubf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e1ac4c-a6be-4ba7-82c5-4e2958e61931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Establish path - assumes user is running this script through Rivanna\n",
    "\n",
    "auxtag  = 'MW_zooms' \n",
    "savetag = 'DREAMS_WDM_zoom'\n",
    "basedir = '/standard/DREAMS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86397c88-b5ef-4ccf-840f-a1e1cbd5bcfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Tree Walking Function\n",
    "\n",
    "def walk_tree(box_to_process, *args):\n",
    "    \"\"\"\n",
    "    This function walks the merger tree within a box. Starts at snapshot 90/redshift 0 with milky way subhalo and \n",
    "    works top to bottom following all branches.\n",
    "    Takes in...\n",
    "    box_to_process: box of interest within SB4 directory.\n",
    "    Returns...\n",
    "    Unique data containers for each data tag.\n",
    "    \"\"\"\n",
    "\n",
    "    # Continue established path to box of interest\n",
    "    datadir = basedir + 'Sims/WDM/'+auxtag+'/SB4/'\n",
    "    grpdir  = basedir + 'FOF_Subfind/WDM/'+auxtag+'/SB4/'\n",
    "    datadir += 'box_%s/' %box_to_process\n",
    "    grpdir  += 'box_%s/' %box_to_process\n",
    "    \n",
    "    # Constants used\n",
    "    snapnrs = 90\n",
    "    little_h = 0.6774\n",
    "\n",
    "    # Establish MW index\n",
    "    keysel = ['SubhaloSFR', 'SubhaloMass','GroupMassType','GroupFirstSub']\n",
    "    cat = rsubf.subfind_catalog( grpdir, snapnrs, keysel=keysel )\n",
    "    central_mass = cat.SubhaloMass[0] * 1.00E+10/little_h\n",
    "    masses = cat.GroupMassType * 1.00E+10/little_h\n",
    "    tot_masses = np.sum(masses,axis=1)\n",
    "    mcut = (tot_masses > 7e11) & (tot_masses < 2.5e12)\n",
    "    contamination = masses[:,2] / tot_masses\n",
    "    idx = np.argmin(contamination[mcut])\n",
    "    mw_idx = np.arange(len(masses))[mcut][idx]\n",
    "    first_sub = cat.GroupFirstSub[mw_idx]\n",
    "\n",
    "    # Load merger tree\n",
    "    with h5py.File( grpdir + 'tree_extended.hdf5', 'r' ) as tree_file:\n",
    "\n",
    "        # Locate MW index within box\n",
    "        all_snaps = np.array(tree_file[\"SnapNum\"])\n",
    "        all_mass  = np.array(tree_file[\"SubhaloMass\"])\n",
    "        at_z0 = all_snaps == 90\n",
    "        mass_at_z0 = np.where(at_z0, all_mass, -1) * 1.00E+10/little_h\n",
    "        subfind_id = np.array(tree_file[\"SubfindID\"])\n",
    "        file_index = np.arange(0,len(subfind_id))[subfind_id==first_sub][0]\n",
    "\n",
    "        # Load data for first subhalo in tree (MW)\n",
    "        # Documentation can be found on https://www.tng-project.org/data/docs/specifications/#sec4a under SubLink.\n",
    "        rootID  = tree_file[\"SubhaloID\"][file_index] # ID in the tree\n",
    "        fpID  = tree_file[\"FirstProgenitorID\"][file_index] # ID of the first progenitor (next most massive subhalo)\n",
    "        current_npID = tree_file[\"NextProgenitorID\"][file_index] # ID of the next progenitor (most massive subhalo after FP)\n",
    "     \n",
    "        # Create containers for data. They begin with the first subhalo's data, in this case the MW, within them. This is because the\n",
    "        # get progenitors function only gets progenitor data, and not current data. To have all the data we need to start with the current subhalo.\n",
    "        containers = [[] for i in args]\n",
    "        for i in range(len(args)):\n",
    "            containers[i].append(tree_file[args[i]][file_index])\n",
    "\n",
    "        # Create a container with initial subhalo indices to walk from. This currently includes MW index and will include as all \n",
    "        # MW next progenitors as well.\n",
    "        initial_subhalo_indices = [file_index]\n",
    "\n",
    "        # While loop over all next progenitors of MW. Not necessary to do the same for FP since get_progenitors loop begins with the initial subhalo's\n",
    "        # first progenitor, and there is a max of one FP.\n",
    "        while current_npID != -1:\n",
    "    \n",
    "            current_npIndex = file_index + (current_npID - rootID)\n",
    "\n",
    "            for i in range(len(args)):\n",
    "                containers[i].append(tree_file[args[i]][current_npIndex])\n",
    "            \n",
    "            initial_subhalo_indices.append(current_npIndex)\n",
    "\n",
    "            \n",
    "            current_npID = tree_file['NextProgenitorID'][current_npIndex]\n",
    "\n",
    "        # Defining a recursive function call within tree walking function. This will allow us to follow each first and next progenitor from each\n",
    "        # previous first and next progenitor, walking the tree top down. To do this we go to the first progenitor, then all of the FPs next progenitors,\n",
    "        # then call the function again on each of those NPs. \n",
    "        def get_progenitors(index,file_index,containers):\n",
    "            \"\"\"\n",
    "            Takes in...\n",
    "            Index: the subhalo index to begin walking the tree with. Function will save all data from all subhalos following this one.\n",
    "            File_index: MW index, used to find progenitor indices.\n",
    "            Lists: data containers to be defined in walking function.\n",
    "            Returns...\n",
    "            Lists: same data containers.\n",
    "            \"\"\"\n",
    "        \n",
    "            fpID = tree_file[\"FirstProgenitorID\"][index] # fpID of the first subhalo.\n",
    "        \n",
    "            # While loop over fpID. Documentation says if fpID = -1, there is no more FP. Each subhalo should have either 1 or 0 FPs.\n",
    "            while fpID != -1:\n",
    "        \n",
    "                fpIndex = file_index + (fpID - rootID) # \"Calculating\" the index of the FP given its subhalo ID. This works for any subhalo index.\n",
    "                \n",
    "                # Get data for each argument based on the FP index and append it to the specific containers.\n",
    "                for i in range(len(args)):\n",
    "                    containers[i].append(tree_file[args[i]][fpIndex])\n",
    "                            \n",
    "                # Get NP ID based on the FP to set up next while loop.\n",
    "                npID = tree_file['NextProgenitorID'][fpIndex]\n",
    "                \n",
    "                # While loop over npID. Each subhalo can any number of NPs. The recursive function will continue walking down this branch as far as\n",
    "                # it goes, and then will come back to the next NP based on the same FP. Then it will walk down that branch and so on.\n",
    "                while npID != -1:\n",
    "        \n",
    "                    npIndex = file_index + (npID - rootID) # \"Calculating\" the index of the NP given its subhalo ID.\n",
    "\n",
    "                    # Get data for each argument based on the NP index and append it to the specific containers.\n",
    "                    for i in range(len(args)):\n",
    "                        containers[i].append(tree_file[args[i]][npIndex])\n",
    "        \n",
    "                    # Calling the function to make it recursive.\n",
    "                    containers = get_progenitors(npIndex,file_index,containers)\n",
    "                    \n",
    "                    # Updating the npID to continue while loop.\n",
    "                    npID = tree_file['NextProgenitorID'][npIndex]\n",
    "        \n",
    "                #Updating the fpID to continue while loop.\n",
    "                fpID = tree_file['FirstProgenitorID'][fpIndex]\n",
    "                    \n",
    "            return containers\n",
    "\n",
    "        # Calling recursive function for each index in the initial indices container. Important to do it in this way to keep the structure of the\n",
    "        # data the same. This way the data is always organized by first progenitor to next progenitor.\n",
    "        for index in initial_subhalo_indices:\n",
    "            \n",
    "            get_progenitors(index,file_index,containers)\n",
    "\n",
    "    return containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f256ac-aba3-4545-a533-3ad9b39d0dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aku7cf/torreylabtoolsPy3/simread/readsubfHDF5.py:178: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  vars(self)[key]=np.empty(self.nsubs, dtype=np.dtype((self.double_type,dim)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "21\n",
      "30\n",
      "42\n",
      "88\n",
      "file not found: /standard/DREAMS/FOF_Subfind/WDM/MW_zooms/SB4/box_428/output/groups_090/snapshot_090.0.hdf5\n",
      "428\n",
      "file not found: /standard/DREAMS/FOF_Subfind/WDM/MW_zooms/SB4/box_502/output/groups_090/snapshot_090.0.hdf5\n",
      "502\n",
      "file not found: /standard/DREAMS/FOF_Subfind/WDM/MW_zooms/SB4/box_576/output/groups_090/snapshot_090.0.hdf5\n",
      "576\n",
      "file not found: /standard/DREAMS/FOF_Subfind/WDM/MW_zooms/SB4/box_864/output/groups_090/snapshot_090.0.hdf5\n",
      "864\n",
      "file not found: /standard/DREAMS/FOF_Subfind/WDM/MW_zooms/SB4/box_1023/output/groups_090/snapshot_090.0.hdf5\n",
      "1023\n"
     ]
    }
   ],
   "source": [
    "## Save SFR and mass data for each box. Note there are a couple missing boxes.\n",
    "\n",
    "boxes = range(1024)\n",
    "SFR_list = []\n",
    "mass_list = []\n",
    "\n",
    "for box in boxes:\n",
    "    try:\n",
    "        SFR,mass = walk_tree(box,\"SubhaloSFR\",\"SubhaloMass\")\n",
    "        SFR_list.append(SFR)\n",
    "        mass_list.append(mass)\n",
    "    except:\n",
    "        print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59debd37-4c1a-47cd-89bc-b8edfde3cd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
